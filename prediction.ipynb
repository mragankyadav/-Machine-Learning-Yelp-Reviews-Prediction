{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2018\n",
    "\n",
    "\n",
    "# Homework 1:  Basic Machine Learning + Learning to Rank \n",
    "\n",
    "### 100 points [5% of your final grade]\n",
    "\n",
    "### Due: Monday, February 12 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* In this homework you will get hands-on experience with (i) the basics of machine learning (e.g. train/test data, cross-validation, different classifiers) and interpreting results; and (ii) learning to rank.\n",
    "\n",
    "*Submission Instructions:* To submit your homework, rename this notebook as UIN_hw#.ipynb. For example, this homework submission would be: YourUIN_hw1.ipynb. Submit this notebook via ecampus. Your notebook should be completely self-contained, with the results visible in the notebook. \n",
    "\n",
    "*Late submission policy:* For this homework, you may use up to three of your late days, meaning that no submissions will be accepted after Thursday, February 15 at 11:59pm.\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Basics of ML (70 points)\n",
    "\n",
    "For this part, we're going to get familiar with scikit-learn (a great ML toolkit that is very popular) and the major issues in training a model, testing it, and interpreting the results. Our goal in this assignment is to build a classifier to determine if a Yelp review is \"food-relevant\" or not.\n",
    "\n",
    "## Dataset: Yelp review data\n",
    "\n",
    "First, you will need to download the training_data.json file from the Resources tab on Piazza, a collection of 40,000 json-encoded Yelp reviews we sampled from the [Yelp Dataset Challenge](https://www.yelp.com/dataset_challenge).\n",
    "\n",
    "You'll see that each line corresponds to a review on a particular business. The label (class) information of each review is in the \"label\" field. It is **either \"Food-relevant\" or \"Food-irrelevant\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Parsing Yelp (15 points)\n",
    "\n",
    "For this first part, we will build a parser for extracting tokens from the **review text** only. First, you should tokenize each review using **whitespaces and punctuations as delimiters**. Do not remove stopwords. You should apply casefolding (lower case everything) and use the [nltk Porter stemmer](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) ... you may need to install nltk if you don't have it already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#Loading data from Json File\n",
    "loaded_data=[]\n",
    "with open('training_data.json') as f:\n",
    "    for review in f:\n",
    "        loaded_data.append(json.loads(review))\n",
    "        \n",
    "#Tokenisation of Reviews based on delimiters and LowerCase Conversion\n",
    "tokenised_lowercased_data=[]\n",
    "for i in loaded_data:\n",
    "    review_text= i['text']\n",
    "    review_label=i['label']\n",
    "    lowercase_text= review_text.lower()\n",
    "    tokenised_text= re.findall(r'[a-zA-Z]+', lowercase_text)\n",
    "    tokenised_lowercased_data.append([review_label,tokenised_text])\n",
    "    \n",
    "#Stemming Using NLTK Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "for tokenised_review in range(len(tokenised_lowercased_data)): \n",
    "    for word in range(len(tokenised_lowercased_data[tokenised_review][1])):\n",
    "        tokenised_lowercased_data[tokenised_review][1][word]=ps.stem(tokenised_lowercased_data[tokenised_review][1][word])\n",
    "        tokenised_lowercased_data[tokenised_review][1][word]=tokenised_lowercased_data[tokenised_review][1][word].encode('utf-8')\n",
    "# print tokenised_lowercased_data[0]\n",
    "# print tokenised_lowercased_data[1]\n",
    "print \"Done\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique tokens?\n",
    "\n",
    "Once you have your parser working, you should report here the size of your feature space. That is, how many unique tokens do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34969\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#Printing the length of feature space/Unique tokens\n",
    "feature_space={}\n",
    "for reviews in tokenised_lowercased_data:\n",
    "    for word in reviews[1]:\n",
    "        if feature_space.get(word,0)==0:\n",
    "            feature_space[word]=1\n",
    "        else:\n",
    "            feature_space[word]+=1\n",
    "print len(feature_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Most Popular Words\n",
    "\n",
    "Great, now we can tokenize the documents. Let's make a list of the most popular words in our reviews. For this step, you should maintain a count of how many times each word occurs. Then you should print out the top-20 words in your reviews.\n",
    "\n",
    "Your output should look like this:\n",
    "\n",
    "Rank Token Count\n",
    "\n",
    "1 awesome 78\n",
    "\n",
    "... ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Token Count\n",
      "   1 the   246313\n",
      "   2 i     168950\n",
      "   3 and   168590\n",
      "   4 a     134996\n",
      "   5 to    128141\n",
      "   6 it    78867\n",
      "   7 of    76237\n",
      "   8 wa    74021\n",
      "   9 is    63499\n",
      "  10 for   60869\n",
      "  11 in    60535\n",
      "  12 that  50804\n",
      "  13 my    50565\n",
      "  14 you   45882\n",
      "  15 they  43635\n",
      "  16 thi   39940\n",
      "  17 with  39340\n",
      "  18 have  39082\n",
      "  19 but   37967\n",
      "  20 on    35388\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import operator\n",
    "#Sorting the token Dictionary and Printing Top 20 tokens\n",
    "sorted_tokens = sorted(feature_space.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print '{0:4s} {1:5s} {2:4s}'.format(\"Rank\", \"Token\",\"Count\")\n",
    "for i in range(20):\n",
    "    print '{0:4d} {1:5s} {2:4d}'.format(i+1, sorted_tokens[i][0], sorted_tokens[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipf's Law\n",
    "\n",
    "Recall in class our discussion of Zipf's law. Let's see if this law applies to our Yelp reviews. You should use matplotlib to plot the log-base10 term counts on the y-axis versus the log-base10 rank on the x-axis. Your aim is to create a figure like the one in Figure 5.2 of the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8057d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Creating Numpy arrays for axis data\n",
    "y_axis = np.array([x[1] for x in sorted_tokens])\n",
    "x_axis = np.array([i for i in range(len(sorted_tokens))])\n",
    "\n",
    "#Adding 1 to everything to remove divison by 0\n",
    "y_axis = y_axis+1\n",
    "x_axis= x_axis+1\n",
    "\n",
    "#Log 10\n",
    "y_axis = np.log10(y_axis)\n",
    "x_axis = np.log10(x_axis)\n",
    "\n",
    "#Plotting\n",
    "plt.xlabel(\"log10 Rank\")\n",
    "plt.ylabel(\"log10 CountFrequncy\")\n",
    "plt.plot(x_axis,y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? Is this consistent with Zipf's law?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the graph is rapidly decreasing. This means that the frequncy of words is decreasing very fast as their rank(in terms of frequency across the reviews) decreases. This is consitent with the Zipf's law which is mainly used to check the distribution of tokens across documents/reviews. It says that if the term with rank 1 has maximum frequqncy, than term with rank 2 will have half its frequqncy and so on, basically stating that frequency decreases rapidly with rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Feature Represenation (10 points)\n",
    "\n",
    "In this part you will build feature vectors for each review. This will be input to our ML classifiers. You should call your parser from earlier, using all the same assumptions (e.g., casefolding, stemming). Each feature value should be the term count for that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "#Created Feature Vectors and Label Vector using SkLearn Vectorizer on the stemmed data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "all_reviews=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    all_reviews.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "vectorizer.fit(all_reviews)\n",
    "review_samples=[]\n",
    "labels=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    review_samples.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "    if tokenised_lowercased_data[i][0]== 'Food-irrelevant':\n",
    "        labels.append(\"Food-irrelevant\")\n",
    "    else:\n",
    "        labels.append(\"Food-relevant\")    \n",
    "feature_vectors=vectorizer.transform(review_samples).toarray()\n",
    "# print feature_vectors\n",
    "# np.set_printoptions(threshold='nan')\n",
    "# print feature_vectors[0]\n",
    "# print feature_vectors[1]\n",
    "# print len(feature_vectors)\n",
    "# print len(feature_vectors[0])\n",
    "# print labels\n",
    "# print len(labels)\n",
    "print \"Done\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Machine Learning Basics (30 points)\n",
    "\n",
    "In this part you will evaluate a bunch of classifiers -- kNN, Decision tree, Naive Bayes, and SVM -- on the feature vectors generated in the previous task in two different settings. **You do not need to implement any classifier from scratch. You may use scikit-learn's built-in capabilities.**\n",
    "\n",
    "### Setting 1: Splitting data into train-test \n",
    "\n",
    "In the first setting, you should treat the first 70% of your data as training. The remaining 30% should be for testing. \n",
    "\n",
    "### Setting 2: Using 5 fold cross-validation\n",
    "\n",
    "In the second setting, use 5-folk cross-validation. \n",
    "\n",
    "### What to report\n",
    "\n",
    "* Report the overall accuracy for both settings.\n",
    "* For the class \"Food-relevant\", report the precision and recall for both settings.\n",
    "* For the class \"Food-irrelevant\", report the precision and recall for both settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here...plus add cells for reporting your results\n",
    "from __future__ import division\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Converting to Sparse Matrix\n",
    "feature_vectors= csr_matrix(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "target_names=[\"Food-irrelevant\",\"Food-relevant\"] # 0:\"Food Irrelevant\", 1:\"Food Relevant\"\n",
    "\n",
    "#kNN\n",
    "def knn(X_train, y_train,X_test,y_test):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    return [accuracy_score(y_test, pred),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-relevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-relevant\"])]   \n",
    "\n",
    "#DecisionTreeClassifier\n",
    "def decisionTree(X_train, y_train,X_test,y_test):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    return [accuracy_score(y_test, pred),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-relevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-relevant\"])] \n",
    "\n",
    "#NaiveBayes\n",
    "def naive_bayes(X_train, y_train,X_test,y_test):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train,y_train)\n",
    "    pred = nb.predict(X_test)\n",
    "    return [accuracy_score(y_test, pred),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-relevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-relevant\"])] \n",
    "\n",
    "#SVM\n",
    "def svm(X_train, y_train,X_test,y_test):\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train,y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    return [accuracy_score(y_test, pred),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-irrelevant\"]),\n",
    "            precision_score(y_test, pred, average=None,labels=[\"Food-relevant\"]),\n",
    "            recall_score(y_test, pred, average=None,labels=[\"Food-relevant\"])] \n",
    "\n",
    "def display_results(result):\n",
    "    print \"Accuracy = \"+str(result[0])\n",
    "    print \"Precision for Food Irrelevant = \" + str(result[1])\n",
    "    print \"Recall for Food Irrelevant = \" + str(result[2])\n",
    "    print \"Precision for Food Relevant = \" + str(result[3])\n",
    "    print \"Recall for Food Relevant = \" + str(result[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70%-30% Split Results\n",
      "\n",
      "KNN Classfier\n",
      "Accuracy = 0.7408333333333333\n",
      "Precision for Food Irrelevant = [0.82866894]\n",
      "Recall for Food Irrelevant = [0.60710118]\n",
      "Precision for Food Relevant = [0.69007232]\n",
      "Recall for Food Relevant = [0.87452091]\n",
      "\n",
      "Naive Bayes Classfier\n",
      "Accuracy = 0.9473333333333334\n",
      "Precision for Food Irrelevant = [0.95413776]\n",
      "Recall for Food Irrelevant = [0.9398233]\n",
      "Precision for Food Relevant = [0.94073223]\n",
      "Recall for Food Relevant = [0.95484086]\n",
      "\n",
      "Decision Tree Classfier\n",
      "Accuracy = 0.8813333333333333\n",
      "Precision for Food Irrelevant = [0.88297338]\n",
      "Recall for Food Irrelevant = [0.87914652]\n",
      "Precision for Food Relevant = [0.87970798]\n",
      "Recall for Food Relevant = [0.88351941]\n",
      "\n",
      "SVM Classfier\n",
      "Accuracy = 0.86875\n",
      "Precision for Food Irrelevant = [0.83333333]\n",
      "Recall for Food Irrelevant = [0.9218203]\n",
      "Precision for Food Relevant = [0.91256525]\n",
      "Recall for Food Relevant = [0.81569738]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Splitting into 70% training and 30% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.3, random_state=42)\n",
    "print \"70%-30% Split Results\"\n",
    "print\n",
    "print \"KNN Classfier\"\n",
    "display_results(knn(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Naive Bayes Classfier\"\n",
    "display_results(naive_bayes(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Decision Tree Classfier\"\n",
    "display_results(decisionTree(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"SVM Classfier\"\n",
    "display_results(svm(X_train, y_train,X_test,y_test))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classfier\n",
      "Accuracy = 0.8551249999999999\n",
      "Precision for Food Irrelevant = [0.87072768]\n",
      "Recall for Food Irrelevant = [0.80388699]\n",
      "Precision for Food Relevant = [0.7209919]\n",
      "Recall for Food Relevant = [0.73127754]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mragank/anaconda2/envs/cs670/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation for KNN\n",
    "kf = KFold(n_splits=5)\n",
    "knnFolds=[0,0,0,0,0]\n",
    "\n",
    "for train_index, test_index in kf.split(feature_vectors):\n",
    "    X_train, X_test = feature_vectors[train_index], feature_vectors[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    knnFolds=[sum(n) for n in zip(*[knnFolds,knn(X_train, y_train,X_test,y_test)])]\n",
    "    \n",
    "print \"KNN Classfier\"\n",
    "display_results([n/5 for n in knnFolds])\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classfier\n",
      "Accuracy = 0.917025\n",
      "Precision for Food Irrelevant = [0.88144026]\n",
      "Recall for Food Irrelevant = [0.92574427]\n",
      "Precision for Food Relevant = [0.76549791]\n",
      "Recall for Food Relevant = [0.73680535]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation for Naive Bayes\n",
    "kf = KFold(n_splits=5)\n",
    "nbFolds=[0,0,0,0,0]\n",
    "\n",
    "for train_index, test_index in kf.split(feature_vectors):\n",
    "    X_train, X_test = feature_vectors[train_index], feature_vectors[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    nbFolds=[sum(n) for n in zip(*[nbFolds,naive_bayes(X_train, y_train,X_test,y_test)])]\n",
    "    \n",
    "print \"Naive Bayes Classfier\"\n",
    "display_results([n/5 for n in nbFolds])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classfier\n",
      "Accuracy = 0.8679\n",
      "Precision for Food Irrelevant = [0.83446453]\n",
      "Recall for Food Irrelevant = [0.86324234]\n",
      "Precision for Food Relevant = [0.73247818]\n",
      "Recall for Food Relevant = [0.70272387]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation for Decision Tree Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "decisionTreeFolds=[0,0,0,0,0]\n",
    "\n",
    "for train_index, test_index in kf.split(feature_vectors):\n",
    "    X_train, X_test = feature_vectors[train_index], feature_vectors[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    decisionTreeFolds=[sum(n) for n in zip(*[decisionTreeFolds,decisionTree(X_train, y_train,X_test,y_test)])]\n",
    "    \n",
    "print \"Decision Tree Classfier\"\n",
    "display_results([n/5 for n in decisionTreeFolds])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation for SVM\n",
    "kf = KFold(n_splits=5)\n",
    "svmFolds=[0,0,0,0,0]\n",
    "for train_index, test_index in kf.split(feature_vectors):\n",
    "    X_train, X_test = feature_vectors[train_index], feature_vectors[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    arr=svm(X_train, y_train,X_test,y_test)\n",
    "    print arr\n",
    "    svmFolds=[sum(n) for n in zip(*[svmFolds,arr])]\n",
    "    \n",
    "print \"SVM Classfier\"\n",
    "display_results([n/5 for n in svmFolds])\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.4: Analyzing your results (5 points) \n",
    "\n",
    "OK, now that you have tried four different classifiers, what do you observe? Any conclusions you can draw? Give us one or two paragraphs summarizing your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried four classifiers as Knn, Naive Bayes, Svm and Decison Tree. The first observation we can make is that naive bayes performs the best in both the settings whether we split it in 70-30 ratio or use cross validation. This may be because we have a really large number of features. We are using Bag-Of-Words model and that created a really large feature space. \n",
    "\n",
    "This large feature space not only makes naive-bayes perform the best, but it is also the fastest. Such large feature space is possibly creating really complex hyper planes due to which models like svm take large amount of time to train. The most important thing about these accuracy and precison measures is that we haven't used any complicated or smart features but a basic BOW model. It has been through multiple research papers that in a BOW model, Naive Bayes performs usually the best and it's hard to beat the performace. \n",
    "\n",
    "Also, we that in K-fold cross validation accuracies for Decision Tree, Naive Bayes and SVM goes down because we are averaging over multiple results where some may be performing worse but in case of KNN, the accuracy goes up.  I think that this is because of irregular data distribution. Since we used default settings while splitting and did not shuffle or proper mixing techniques, there is a very high chance that while splitting we took majority of one class in the training split while other class in testing split. \n",
    "\n",
    "So based on this data and the results, I can say that it's important to balance the data in term of class distribution and also randomize the order. Specially, in K-fold svm we see a serious drop in accuracy which is due to very low precision and recall values in relevant food items. This is a clear indication of uneven data distribution cause I found that we get a high accuray for SVM in only one fold where that fold probably has better distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5: Improving your classifier (10 points)\n",
    "\n",
    "I think we can do better! In this part, your job is to create new features that you can think can help improve your classifier. You may choose to use new weightings for your words, new derived features (e.g., count of 3-letter words), or whatever you like. You may also add in the extra features in the json: funny, useful, cool. You will need to experiment with different approaches ... once you finalize on your best approach, include the features here with a description (that is, tell us what the feature means). Then give us your classifier results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Features\n",
    "I have made three modifications in the above BOW model\n",
    "\n",
    "First Feature Detail: I have added weightage to all the words using TF-IDF. It ensures that very frequent words which are found in most of the reiews does not adversely affect the classification. It assigns high weights to less frequent words and low weights vice versa.\n",
    "\n",
    "Second Feature Detail: I have removed all the stop words from the reviews. As we saw previously, majority of the words were stop words that don't really make a difference in classification so removing them reduces the feature space and helps relevant words to affect the model more in the correct way.\n",
    "\n",
    "Third Feature Detail: I have used feature elimination to reduce the number of features from 30000 to 1000 thus reducing the number of features to mere 30% of the original. I selected the best 1000 features of all and used only them.\n",
    "The code and the results after adding these 3 features in a compunded manner are given below.\n",
    "\n",
    "Results are shown below with the code. We can see that with every feature, accuracy for all the classfiers kept going up so we can say that all the new introduced modifications were good features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Results with TF-IDF Weightage\n",
      "\n",
      "KNN Classfier\n",
      "Accuracy = 0.9070833333333334\n",
      "Precision for Food Irrelevant = [0.96355353]\n",
      "Recall for Food Irrelevant = [0.84614102]\n",
      "Precision for Food Relevant = [0.86289364]\n",
      "Recall for Food Relevant = [0.96800533]\n",
      "\n",
      "Naive Bayes Classfier\n",
      "Accuracy = 0.9499166666666666\n",
      "Precision for Food Irrelevant = [0.95270044]\n",
      "Recall for Food Irrelevant = [0.94682447]\n",
      "Precision for Food Relevant = [0.94716794]\n",
      "Recall for Food Relevant = [0.95300783]\n",
      "\n",
      "Decision Tree Classfier\n",
      "Accuracy = 0.8798333333333334\n",
      "Precision for Food Irrelevant = [0.88339223]\n",
      "Recall for Food Irrelevant = [0.87514586]\n",
      "Precision for Food Relevant = [0.87634142]\n",
      "Recall for Food Relevant = [0.88451925]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here ... add as many cells as you need for features, results, and discussion.\n",
    "\n",
    "#TF-IDF for Word Weightage Assignment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "all_reviews=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    all_reviews.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "tf.fit(all_reviews)\n",
    "review_samples=[]\n",
    "labels=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    review_samples.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "    if tokenised_lowercased_data[i][0]== 'Food-irrelevant':\n",
    "        labels.append(\"Food-irrelevant\")\n",
    "    else:\n",
    "        labels.append(\"Food-relevant\")   \n",
    "feature_vectors=tf.transform(review_samples).toarray()\n",
    "feature_vectors= csr_matrix(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.3, random_state=42)\n",
    "print \"Split Results with TF-IDF Weightage\"\n",
    "print\n",
    "print \"KNN Classfier\"\n",
    "display_results(knn(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Naive Bayes Classfier\"\n",
    "display_results(naive_bayes(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Decision Tree Classfier\"\n",
    "display_results(decisionTree(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Results with Stop Words Removed from TF-IDF\n",
      "\n",
      "KNN Classfier\n",
      "Accuracy = 0.9046666666666666\n",
      "Precision for Food Irrelevant = [0.95827827]\n",
      "Recall for Food Irrelevant = [0.84614102]\n",
      "Precision for Food Relevant = [0.86230046]\n",
      "Recall for Food Relevant = [0.9631728]\n",
      "\n",
      "Naive Bayes Classfier\n",
      "Accuracy = 0.9511666666666667\n",
      "Precision for Food Irrelevant = [0.95663911]\n",
      "Recall for Food Irrelevant = [0.94515753]\n",
      "Precision for Food Relevant = [0.94582579]\n",
      "Recall for Food Relevant = [0.9571738]\n",
      "\n",
      "Decision Tree Classfier\n",
      "Accuracy = 0.89375\n",
      "Precision for Food Irrelevant = [0.90307167]\n",
      "Recall for Food Irrelevant = [0.88214702]\n",
      "Precision for Food Relevant = [0.88485342]\n",
      "Recall for Food Relevant = [0.90534911]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removing all stop words from TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "all_reviews=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    all_reviews.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "tf.fit(all_reviews)\n",
    "review_samples=[]\n",
    "labels=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    review_samples.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "    if tokenised_lowercased_data[i][0]== 'Food-irrelevant':\n",
    "        labels.append(\"Food-irrelevant\")\n",
    "    else:\n",
    "        labels.append(\"Food-relevant\")   \n",
    "feature_vectors=tf.transform(review_samples).toarray()\n",
    "feature_vectors= csr_matrix(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.3, random_state=42)\n",
    "print \"Split Results with Stop Words Removed from TF-IDF\"\n",
    "print\n",
    "print \"KNN Classfier\"\n",
    "display_results(knn(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Naive Bayes Classfier\"\n",
    "display_results(naive_bayes(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Decision Tree Classfier\"\n",
    "display_results(decisionTree(X_train, y_train,X_test,y_test))\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Results with K-Best(1000) Features Only\n",
      "\n",
      "KNN Classfier\n",
      "Accuracy = 0.9046666666666666\n",
      "Precision for Food Irrelevant = [0.95827827]\n",
      "Recall for Food Irrelevant = [0.84614102]\n",
      "Precision for Food Relevant = [0.86230046]\n",
      "Recall for Food Relevant = [0.9631728]\n",
      "\n",
      "Naive Bayes Classfier\n",
      "Accuracy = 0.9511666666666667\n",
      "Precision for Food Irrelevant = [0.95663911]\n",
      "Recall for Food Irrelevant = [0.94515753]\n",
      "Precision for Food Relevant = [0.94582579]\n",
      "Recall for Food Relevant = [0.9571738]\n",
      "\n",
      "Decision Tree Classfier\n",
      "Accuracy = 0.893\n",
      "Precision for Food Irrelevant = [0.9027849]\n",
      "Recall for Food Irrelevant = [0.88081347]\n",
      "Precision for Food Relevant = [0.8836831]\n",
      "Recall for Food Relevant = [0.90518247]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reducing the number of features from 30000 to 1000 best features.\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "all_reviews=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    all_reviews.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "tf.fit(all_reviews)\n",
    "review_samples=[]\n",
    "labels=[]\n",
    "for i in range(len(tokenised_lowercased_data)):\n",
    "    review_samples.append(' '.join(tokenised_lowercased_data[i][1]))\n",
    "    if tokenised_lowercased_data[i][0]== 'Food-irrelevant':\n",
    "        labels.append(\"Food-irrelevant\")\n",
    "    else:\n",
    "        labels.append(\"Food-relevant\")   \n",
    "feature_vectors=tf.transform(review_samples).toarray()\n",
    "newfeature_vectors = SelectKBest(chi2, k=1000).fit_transform(feature_vectors, labels)\n",
    "feature_vectors= csr_matrix(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.3, random_state=42)\n",
    "print \"Split Results with K-Best(1000) Features Only\"\n",
    "print\n",
    "print \"KNN Classfier\"\n",
    "display_results(knn(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Naive Bayes Classfier\"\n",
    "display_results(naive_bayes(X_train, y_train,X_test,y_test))\n",
    "print\n",
    "print \"Decision Tree Classfier\"\n",
    "display_results(decisionTree(X_train, y_train,X_test,y_test))\n",
    "print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: What are the most informative features in distinguishing these two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Learning to Rank (30 points)\n",
    "\n",
    "For this part, we're going to play with some Microsoft LETOR data that has query-document relevance judgments. Let's see how learning to rank works in practice. \n",
    "\n",
    "First, you will need to download the MQ2008.zip file from the Resources tab on Piazza. This is data from the [Microsoft Research IR Group](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/).\n",
    "\n",
    "The data includes 15,211 rows. Each row is a query-document pair. The first column is a relevance label of this pair (0,1 or 2--> the higher value the more related), the second column is query id, the following columns are features, and the end of the row is comment about the pair, including id of the document. A query-document pair is represented by a 46-dimensional feature vector. Features are a numeric value describing a document and query such as TFIDF, BM25, Page Rank, .... You can find compelete description of features from [here](https://arxiv.org/ftp/arxiv/papers/1306/1306.2597.pdf).\n",
    "\n",
    "The good news for you is the dataset is ready for analysis: It has already been split into 5 folds (see the five folders called Fold1, ..., Fold5).\n",
    "\n",
    "For this assignment, we're going to leave our favorite scikit-learn and instead use [SVM-rank](https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html). This is the basic ranking SVM we talked about in class. You'll see that SVM-rank considers pairwise relevance between docs -- so based on the training data it will transform the data into pairs -- like D1 > D2 and then learn a separator.\n",
    "\n",
    "\n",
    "## Part 2.1: Optimizing SVM-Rank (15 points)\n",
    "\n",
    "First, you should explore how the different parameters affect the quality of the Ranking SVM. You'll see that you can vary the kernel function, the loss function and so forth. \n",
    "\n",
    "You should run SVM-Rank using the default options over each of the five folds. You should find the error on the test set (for example, depending on your settings, svm_rank_classify will give you the zero/one error statistics (that is, the number of correct pairs and the number of incorrect pairs). Report the average. \n",
    "\n",
    "Then try different parameters and report how they impact the quality of results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran SVM-rank for all the folds and here are zero-one error results for all the folds along with the average:\n",
    "Fold 1 Zero/one-error on test set: 58.97%\n",
    "Fold 2 Zero/one-error on test set: 57.32%\n",
    "Fold 3 Zero/one-error on test set: 61.15% \n",
    "Fold 4 Zero/one-error on test set: 60.51% \n",
    "Fold 5 Zero/one-error on test set: 64.97%\n",
    "Average Zero/one-error: 60.58%\n",
    "\n",
    "All the above error values are for default settings \n",
    "\n",
    "I played around with the C-Values(trade-off between training error and margin), loss functions and different kernal options.  Here are my observations:\n",
    "For C-Values, here are some error values for different C values:\n",
    "C= 0.01 Error=56.05%\n",
    "C= 1    Error=55.41%\n",
    "C= 3    Error=57.32%\n",
    "C= 6    Error=56.69% \n",
    "C= 9    Error=57.96% \n",
    "C=15    Error=56.05%\n",
    "So for values of C we can observe that th error percentage kept on increasing and then it decreased as we kept increasing the value of C\n",
    "\n",
    "I also ran the SVM-rank using different kernals(t value). I saw that linear kernal(t=0) gives the minimum error value. \n",
    "For other kernal values, we got the following error values:\n",
    "t=2(Radial Basis) Error= 63.69%\n",
    "t=3(Sigmoid)      Error= 64.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2.1: Noise! (15 points)\n",
    "\n",
    "Now we're going to investigate whether the ranking SVM is easily influenced by noisy features. For example, what if some of the features you have are in error? Or what if you downloaded only a portion of a page to calculate a feature? (so the count of inlinks would be wrong)? \n",
    "\n",
    "In this case, add some noise to the features. What happens to the results? You may choose to add random noise throughout, noise to a single feature, noise to multiple features, etc. The choices are up to you. We aim to see what kind of exploration you conduct and what you conclude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added noise to the features in the following manners:\n",
    "1. Added random values between (0,1) to first 18 features\n",
    "2. Added random values between (0,1) to first 35 features\n",
    "3. Added random values between (0,10) to first 15 features\n",
    "4. Added random values between (1,10) to all features\n",
    "5. Added only 60% of queries (Incomplete File Download case)\n",
    "Observation:  Adding Noise does not really impact the Zero/One Error Values. the error value reamined contant as 56.05%. It deflected to 56.69% in case 2nd change as mentioned above but that is very marginal difference and I wont call it any substantial change due to noise. \n",
    "\n",
    "I added noise using a python code which I have added below. It will not run here since it needs input training files to modify but you can get the idea regarding how I modified the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "newFile=open(\"/Users/Mragank/Desktop/MQ2008_2/Fold2/newtrain.txt\",'w+')\n",
    "with open('/Users/Mragank/Desktop/MQ2008_2/Fold2/train.txt') as f:\n",
    "    for review in f:\n",
    "        query_pair=review.split()\n",
    "        modified_line=[]\n",
    "        #Change the value of this range to modify more features maximum being 46.\n",
    "        for i in range(2,30):\n",
    "            val=query_pair[i].split(':')\n",
    "            # Change the values in uniform to add random noise\n",
    "            v= float(val[1])+random.uniform(0,10)\n",
    "            newpair=':'.join([val[0],str(v)])\n",
    "            modified_line.append(newpair)\n",
    "        for i in range(len(query_pair)):\n",
    "            if(i>=2 and i<30):\n",
    "                newFile.write(modified_line[i-2]+\" \")\n",
    "            else:\n",
    "                newFile.write(query_pair[i]+\" \")\n",
    "        newFile.write(\"\\n\")\n",
    "newFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you collaborated with anyone (see Collaboration policy at the top of this homework), you can put your collaboration declarations here.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
